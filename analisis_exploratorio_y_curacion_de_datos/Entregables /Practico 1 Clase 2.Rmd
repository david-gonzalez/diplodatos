---
title: "Entreglable clase 2"
author: "Facundo Díaz Cobos - David Gonzalez"
date: "5/6/2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


## Ejercicios. Práctico 1

Los valores correctos estan en la diagonal de la matriz, 98% de precision para unas pocas lineas de R!

+ Mejore el rendimiento utilizando una normalizacion con z-scores provista por la funcion scale() de R.

+ Pruebe algunos valores alternativos de k=1, 5,  11, 15, 21 y seleccione el mejor valor de k.

+ mientras termina su merecido cafe verifique si el resultado cambia utilizando paciente elegidos aleatoriamente para el conjunto de validacion.


```{r}
# Práctico 1:
# Leemos el Dataset y sus caracteristicas principales.
ds = read.csv("http://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data",header=FALSE)
ds = ds[-1]
ds
summary(ds)

table(ds$V2)
str(ds)

```

Creamos la funcion para normalizar los valores, para que valores más altos no influyan mas a la hora de clasificar

```{r}
# Función de normalizacion.
normalize <- function(x) {
  return ((x-min(x))/(max(x)-min(x)))
}
```


Aplicamos la funcion de normalizar al dataset

```{r}
ds_normalizado <- as.data.frame(lapply(ds[2:31], normalize))
ds_normalizado
```

Se dividen los datos en datos para entrenamiento y datos para probar el algoritmo.

A su vez hay que sacar el "label"", para entrenar

```{r}
data_train <- ds_normalizado[1:469, ]
data_test <- ds_normalizado[470:569, ]

# Excluimos la variable objetivo (Benigno/Maligno), pero necesitamos guardar estos factores en vectores!
  
data_train_labels <- ds[1:469, 1]
data_test_labels <- ds[470:569, 1]


```

Entrenamos el algoritmo

```{r}
library(class)
data_test_pred <- knn(train=data_train, test=data_test, cl=data_train_labels, k=21)
```


vemosque tan bien funciono el clasificador.
```{r}
library(gmodels)
CrossTable(x=data_test_labels, y=data_test_pred, prop.chisq = FALSE)
```

En vez de normalizar las variables vamos a escalarlas usando z-score y la funcion scale que ya traen las librerias de R y vemos si mejora.

```{r}
ds_z_score <- scale(ds[-1])
data_train <- ds_z_score[1:469, ]
data_test <- ds_z_score[470:569, ]
data_train_labels <- ds[1:469, 1]
data_test_labels <- ds[470:569, 1]
library(class)
data_test_pred_k21 <- knn(train=data_train, test=data_test, cl=data_train_labels, k=21)
library(gmodels)

CrossTable(x=data_test_labels, y=data_test_pred_k21, prop.chisq = FALSE)
```
En con 100 valores de prueba, no mejoró el rendimiento pero si cambiamos las muestras para entrenar y validar si tiene mejoras.
Ahora vamos a probar con diferentes k.

---


Ahora vamos a probar con diferentes valores de K.
```{r}
ds_z_score <- scale(ds[-1])
data_train <- ds_z_score[1:469, ]
data_test <- ds_z_score[470:569, ]
data_train_labels <- ds[1:469, 1]
data_test_labels <- ds[470:569, 1]
library(class)
data_test_pred_k1 <- knn(train=data_train, test=data_test, cl=data_train_labels, k=1)
data_test_pred_k5 <- knn(train=data_train, test=data_test, cl=data_train_labels, k=5)
data_test_pred_k11 <- knn(train=data_train, test=data_test, cl=data_train_labels, k=11)
data_test_pred_k15 <- knn(train=data_train, test=data_test, cl=data_train_labels, k=15)
data_test_pred_k21 <- knn(train=data_train, test=data_test, cl=data_train_labels, k=21)
library(gmodels)
CrossTable(x=data_test_labels, y=data_test_pred_k1, prop.chisq = FALSE)
CrossTable(x=data_test_labels, y=data_test_pred_k5, prop.chisq = FALSE)
CrossTable(x=data_test_labels, y=data_test_pred_k11, prop.chisq = FALSE)
CrossTable(x=data_test_labels, y=data_test_pred_k15, prop.chisq = FALSE)
CrossTable(x=data_test_labels, y=data_test_pred_k21, prop.chisq = FALSE)
```

Los diferentes valores de K, nos dieron diferentes resultados. Por ejemplo con valores chicos de K, fueron mas los falsos negativos
y con valores mas altos fueron mas los falsos positivos. y con k =11, hubo un falso positivo y un solo falso negativo.


Ahora vamos a randomizar el orden: 
```{r}
ds <- ds[sample(1:nrow(ds)), ]
ds_z_score <- scale(ds[-1])

ds_z_score <- scale(ds[-1])
data_train <- ds_z_score[101:569, ]
data_test <- ds_z_score[1:100, ]
data_train_labels <- ds[101:569, 1]
data_test_labels <- ds[1:100, 1]
library(class)
library(gmodels)
data_test_pred_k15 <- knn(train=data_train, test=data_test, cl=data_train_labels, k=15)

CrossTable(x=data_test_labels, y=data_test_pred_k15, prop.chisq = FALSE)
```

Con el Orden random, vemos que es muy influyente a la hora de clasificar, por lo que podemos advertir que necesitamos mas datos para entrenar y probar el algoritmo clasificador.

